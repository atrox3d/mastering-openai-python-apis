{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "## openai helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt:str, model:str='gpt-4o-mini', return_dict_body:bool=False, return_response_body:bool=False) -> str | dict | ChatCompletion:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # print(type(response))\n",
    "    \n",
    "    if return_response_body:\n",
    "        return response\n",
    "    if return_dict_body:\n",
    "        return response.model_dump()\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template interpolate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_prompt(prompt:str) -> str:\n",
    "    return f'''\n",
    "    You are a color palette generating assistant that responds to text prompts for color palettes\n",
    "    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\n",
    "    The palettes should be between 2 and 8 colors, the more the better.\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\n",
    "    A: [\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\n",
    "    A: [\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]\n",
    "\n",
    "\n",
    "    Desired Format: just a JSON array of hexadecimal color codes, nothing else before or after\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: {prompt}\n",
    "    A:    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook markdown display helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colors(colors, width:int=4):\n",
    "    display(\n",
    "        Markdown(\n",
    "            ' '.join(\n",
    "                f'<span style=\"color: {color}\">{chr(9608) * width}</span>'\n",
    "                for color in colors\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main\n",
    "## get json color array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"#0077BE\", \"#00BFFF\", \"#1E90FF\", \"#5F9EA0\", \"#ADD8E6\"]'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_llm_response(\n",
    "    get_colors_prompt('blue ocean')\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert json to python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#0077BE', '#00BFFF', '#1E90FF', '#5F9EA0', '#ADD8E6']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = json.loads(response)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #0077BE\">████</span> <span style=\"color: #00BFFF\">████</span> <span style=\"color: #1E90FF\">████</span> <span style=\"color: #5F9EA0\">████</span> <span style=\"color: #ADD8E6\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_colors(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# macro helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "\n",
    "\n",
    "def show_palette(prompt:str):\n",
    "    try:\n",
    "        userprompt = get_colors_prompt(prompt)\n",
    "        response = get_llm_response(userprompt)\n",
    "        colors = json.loads(response)\n",
    "        display_colors(colors)\n",
    "        print(colors)\n",
    "    except JSONDecodeError as jde:\n",
    "        print(f'something wrong with llm response format: {response!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #003D5B\">████</span> <span style=\"color: #006B83\">████</span> <span style=\"color: #0B8B9B\">████</span> <span style=\"color: #12B0A8\">████</span> <span style=\"color: #D9BF77\">████</span> <span style=\"color: #F9AFAF\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#003D5B', '#006B83', '#0B8B9B', '#12B0A8', '#D9BF77', '#F9AFAF']\n"
     ]
    }
   ],
   "source": [
    "show_palette('ocean abyss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #00FF00\">████</span> <span style=\"color: #1F1F1F\">████</span> <span style=\"color: #333333\">████</span> <span style=\"color: #66FF66\">████</span> <span style=\"color: #AFAFAF\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#00FF00', '#1F1F1F', '#333333', '#66FF66', '#AFAFAF']\n"
     ]
    }
   ],
   "source": [
    "show_palette('cyber terminal with green chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #F6EB61\">████</span> <span style=\"color: #F4C300\">████</span> <span style=\"color: #BAE4EA\">████</span> <span style=\"color: #D69A20\">████</span> <span style=\"color: #C41400\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#F6EB61', '#F4C300', '#BAE4EA', '#D69A20', '#C41400']\n"
     ]
    }
   ],
   "source": [
    "show_palette('spongebob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #C8102E\">████</span> <span style=\"color: #005EB8\">████</span> <span style=\"color: #F7EA00\">████</span> <span style=\"color: #FFFFFF\">████</span> <span style=\"color: #000000\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#C8102E', '#005EB8', '#F7EA00', '#FFFFFF', '#000000']\n"
     ]
    }
   ],
   "source": [
    "show_palette('superman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
