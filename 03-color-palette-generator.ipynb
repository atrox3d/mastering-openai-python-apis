{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "## openai helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt:str, model:str='gpt-4o-mini', return_dict_body:bool=False, return_response_body:bool=False) -> str | dict | ChatCompletion:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # print(type(response))\n",
    "    \n",
    "    if return_response_body:\n",
    "        return response\n",
    "    if return_dict_body:\n",
    "        return response.model_dump()\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template interpolate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_prompt(prompt:str) -> str:\n",
    "    return f'''\n",
    "    You are a color palette generating assistant that responds to text prompts for color palettes\n",
    "    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\n",
    "    The palettes should be between 2 and 8 colors, the more the better.\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\n",
    "    A: [\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\n",
    "    A: [\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]\n",
    "\n",
    "\n",
    "    Desired Format: just a JSON array of hexadecimal color codes, nothing else before or after\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: {prompt}\n",
    "    A:    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook markdown display helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colors(colors, width:int=4):\n",
    "    display(\n",
    "        Markdown(\n",
    "            ' '.join(\n",
    "                f'<span style=\"color: {color}\">{chr(9608) * width}</span>'\n",
    "                for color in colors\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main\n",
    "## get json color array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"#003C71\", \"#0091B5\", \"#00B2E2\", \"#53C8D5\", \"#A2E4E6\"]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_llm_response(\n",
    "    get_colors_prompt('blue ocean')\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert json to python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#003C71', '#0091B5', '#00B2E2', '#53C8D5', '#A2E4E6']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = json.loads(response)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #003C71\">████</span> <span style=\"color: #0091B5\">████</span> <span style=\"color: #00B2E2\">████</span> <span style=\"color: #53C8D5\">████</span> <span style=\"color: #A2E4E6\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_colors(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# macro helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_palette(prompt:str):\n",
    "    display_colors(\n",
    "        json.loads(\n",
    "            get_llm_response(\n",
    "                get_colors_prompt(prompt)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #1B3A57\">████</span> <span style=\"color: #3B6B8C\">████</span> <span style=\"color: #4EA2A1\">████</span> <span style=\"color: #A4D4D4\">████</span> <span style=\"color: #F2F5F7\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_palette('ocean abyss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #00FF00\">████</span> <span style=\"color: #1E1E1E\">████</span> <span style=\"color: #A0A0A0\">████</span> <span style=\"color: #003300\">████</span> <span style=\"color: #007F00\">████</span> <span style=\"color: #00FF7F\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_palette('cyber terminal with green chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #F9D74E\">████</span> <span style=\"color: #F8A300\">████</span> <span style=\"color: #C6D3F8\">████</span> <span style=\"color: #6D5F71\">████</span> <span style=\"color: #F17B3B\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_palette('spongebob')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
