{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import dotenv_values, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give some money to openai\n"
     ]
    }
   ],
   "source": [
    "from openai import RateLimitError\n",
    "\n",
    "\n",
    "try:\n",
    "    reply = client.completions.create(\n",
    "        prompt='test',\n",
    "        model=\"davinci-002\",\n",
    "        \n",
    "    )\n",
    "\n",
    "    reply\n",
    "except RateLimitError as rle:\n",
    "    print('give some money to openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-B6sOrGfD0yFg6nYZxMBKbyEOU34tT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The cat says \"meow\"! Is there something specific you\\'d like to know about cats or their behavior?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740978781, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_06737a9306', usage=CompletionUsage(completion_tokens=22, prompt_tokens=11, total_tokens=33, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"the cat says \",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # model=\"davinci-002\",\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-B6sOrGfD0yFg6nYZxMBKbyEOU34tT\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"The cat says \\\"meow\\\"! Is there something specific you'd like to know about cats or their behavior?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1740978781,\n",
      "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": \"fp_06737a9306\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 22,\n",
      "        \"prompt_tokens\": 11,\n",
      "        \"total_tokens\": 33,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"completion_tokens\": 22,\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"total_tokens\": 33,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response.usage.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.Choice"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-B6sPCeBAP19L9343kH6zm0jNb4jMG',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': {'content': [{'token': 'As',\n",
       "      'bytes': [65, 115],\n",
       "      'logprob': -0.0009240844519808888,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' my',\n",
       "      'bytes': [32, 109, 121],\n",
       "      'logprob': -0.05630997568368912,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' last',\n",
       "      'bytes': [32, 108, 97, 115, 116],\n",
       "      'logprob': -0.0006320207612589002,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' knowledge',\n",
       "      'bytes': [32, 107, 110, 111, 119, 108, 101, 100, 103, 101],\n",
       "      'logprob': -0.6996397376060486,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' update',\n",
       "      'bytes': [32, 117, 112, 100, 97, 116, 101],\n",
       "      'logprob': -0.000939450750593096,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' in',\n",
       "      'bytes': [32, 105, 110],\n",
       "      'logprob': -0.0059370906092226505,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' October',\n",
       "      'bytes': [32, 79, 99, 116, 111, 98, 101, 114],\n",
       "      'logprob': -3.6550729419104755e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ', 'bytes': [32], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '202',\n",
       "      'bytes': [50, 48, 50],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '3',\n",
       "      'bytes': [51],\n",
       "      'logprob': -0.8259438276290894,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': -0.023291829973459244,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' most',\n",
       "      'bytes': [32, 109, 111, 115, 116],\n",
       "      'logprob': -0.9444934725761414,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' populated',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 101, 100],\n",
       "      'logprob': -0.029852891340851784,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' cities',\n",
       "      'bytes': [32, 99, 105, 116, 105, 101, 115],\n",
       "      'logprob': -8.613945101387799e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' in',\n",
       "      'bytes': [32, 105, 110],\n",
       "      'logprob': -0.21897806227207184,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': -0.00015955790877342224,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' world',\n",
       "      'bytes': [32, 119, 111, 114, 108, 100],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' can',\n",
       "      'bytes': [32, 99, 97, 110],\n",
       "      'logprob': -0.1870611310005188,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' vary',\n",
       "      'bytes': [32, 118, 97, 114, 121],\n",
       "      'logprob': -0.12132573127746582,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' based',\n",
       "      'bytes': [32, 98, 97, 115, 101, 100],\n",
       "      'logprob': -1.0480239391326904,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' on',\n",
       "      'bytes': [32, 111, 110],\n",
       "      'logprob': -4.008129963040119e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': -0.8168595433235168,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' criteria',\n",
       "      'bytes': [32, 99, 114, 105, 116, 101, 114, 105, 97],\n",
       "      'logprob': -0.1653328537940979,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' used',\n",
       "      'bytes': [32, 117, 115, 101, 100],\n",
       "      'logprob': -0.008593295700848103,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' (',\n",
       "      'bytes': [32, 40],\n",
       "      'logprob': -0.03549182042479515,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'city',\n",
       "      'bytes': [99, 105, 116, 121],\n",
       "      'logprob': -0.14460153877735138,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' proper',\n",
       "      'bytes': [32, 112, 114, 111, 112, 101, 114],\n",
       "      'logprob': -0.0016867241356521845,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -0.024684278294444084,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' metropolitan',\n",
       "      'bytes': [32, 109, 101, 116, 114, 111, 112, 111, 108, 105, 116, 97, 110],\n",
       "      'logprob': -0.004342887084931135,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' area',\n",
       "      'bytes': [32, 97, 114, 101, 97],\n",
       "      'logprob': -9.17420256882906e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -7.398067828034982e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' or',\n",
       "      'bytes': [32, 111, 114],\n",
       "      'logprob': -2.74566650390625,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' urban',\n",
       "      'bytes': [32, 117, 114, 98, 97, 110],\n",
       "      'logprob': -0.000585918256547302,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ag',\n",
       "      'bytes': [32, 97, 103],\n",
       "      'logprob': -0.8260664939880371,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'glomer',\n",
       "      'bytes': [103, 108, 111, 109, 101, 114],\n",
       "      'logprob': -2.165027217415627e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'ation',\n",
       "      'bytes': [97, 116, 105, 111, 110],\n",
       "      'logprob': -2.463036435074173e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ').',\n",
       "      'bytes': [41, 46],\n",
       "      'logprob': -0.024544933810830116,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' However',\n",
       "      'bytes': [32, 72, 111, 119, 101, 118, 101, 114],\n",
       "      'logprob': -0.08447998017072678,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',', 'bytes': [44], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' as',\n",
       "      'bytes': [32, 97, 115],\n",
       "      'logprob': -3.81913161277771,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.29739728569984436,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' that',\n",
       "      'bytes': [32, 116, 104, 97, 116],\n",
       "      'logprob': -0.4160620868206024,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' time',\n",
       "      'bytes': [32, 116, 105, 109, 101],\n",
       "      'logprob': -0.22675201296806335,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -0.0005458841915242374,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' here',\n",
       "      'bytes': [32, 104, 101, 114, 101],\n",
       "      'logprob': -0.9987260103225708,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' are',\n",
       "      'bytes': [32, 97, 114, 101],\n",
       "      'logprob': -0.37187719345092773,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' generally',\n",
       "      'bytes': [32, 103, 101, 110, 101, 114, 97, 108, 108, 121],\n",
       "      'logprob': -2.5915303230285645,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' considered',\n",
       "      'bytes': [32, 99, 111, 110, 115, 105, 100, 101, 114, 101, 100],\n",
       "      'logprob': -0.5458602905273438,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' some',\n",
       "      'bytes': [32, 115, 111, 109, 101],\n",
       "      'logprob': -1.9195456504821777,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -4.320199877838604e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' most',\n",
       "      'bytes': [32, 109, 111, 115, 116],\n",
       "      'logprob': -0.22620244324207306,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' populated',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 101, 100],\n",
       "      'logprob': -0.06209137663245201,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' cities',\n",
       "      'bytes': [32, 99, 105, 116, 105, 101, 115],\n",
       "      'logprob': -0.008036931976675987,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' (',\n",
       "      'bytes': [32, 40],\n",
       "      'logprob': -2.12859845161438,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'by',\n",
       "      'bytes': [98, 121],\n",
       "      'logprob': -0.6778568029403687,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' metropolitan',\n",
       "      'bytes': [32, 109, 101, 116, 114, 111, 112, 111, 108, 105, 116, 97, 110],\n",
       "      'logprob': -0.03723336383700371,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' area',\n",
       "      'bytes': [32, 97, 114, 101, 97],\n",
       "      'logprob': -0.001296662027016282,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '):\\n\\n',\n",
       "      'bytes': [41, 58, 10, 10],\n",
       "      'logprob': -0.29528120160102844,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '1', 'bytes': [49], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': -0.02975917048752308,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Tokyo',\n",
       "      'bytes': [84, 111, 107, 121, 111],\n",
       "      'logprob': -0.00015359772078227252,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -0.0018815194489434361,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Japan',\n",
       "      'bytes': [32, 74, 97, 112, 97, 110],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**',\n",
       "      'bytes': [42, 42],\n",
       "      'logprob': -0.5759821534156799,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -0.11566072702407837,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' A',\n",
       "      'bytes': [32, 65],\n",
       "      'logprob': -6.962285041809082,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' major',\n",
       "      'bytes': [32, 109, 97, 106, 111, 114],\n",
       "      'logprob': -1.2613011598587036,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' metropolitan',\n",
       "      'bytes': [32, 109, 101, 116, 114, 111, 112, 111, 108, 105, 116, 97, 110],\n",
       "      'logprob': -2.94395112991333,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' area',\n",
       "      'bytes': [32, 97, 114, 101, 97],\n",
       "      'logprob': -0.007936762645840645,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' with',\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'logprob': -0.13868971168994904,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.01789201982319355,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.06814118474721909,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -1.8689887523651123,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' around',\n",
       "      'bytes': [32, 97, 114, 111, 117, 110, 100],\n",
       "      'logprob': -2.6298558712005615,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -2.339278580620885e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '37',\n",
       "      'bytes': [51, 55],\n",
       "      'logprob': -0.0004158953088335693,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -0.0007842566701583564,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.38817259669303894,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '2',\n",
       "      'bytes': [50],\n",
       "      'logprob': -8.709308167453855e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Delhi',\n",
       "      'bytes': [68, 101, 108, 104, 105],\n",
       "      'logprob': -0.0003884894831571728,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',', 'bytes': [44], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' India',\n",
       "      'bytes': [32, 73, 110, 100, 105, 97],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -4.0722858102526516e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' The',\n",
       "      'bytes': [32, 84, 104, 101],\n",
       "      'logprob': -1.1666125059127808,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' capital',\n",
       "      'bytes': [32, 99, 97, 112, 105, 116, 97, 108],\n",
       "      'logprob': -0.10738315433263779,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' city',\n",
       "      'bytes': [32, 99, 105, 116, 121],\n",
       "      'logprob': -3.0779097080230713,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' and',\n",
       "      'bytes': [32, 97, 110, 100],\n",
       "      'logprob': -2.0130062103271484,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' its',\n",
       "      'bytes': [32, 105, 116, 115],\n",
       "      'logprob': -0.8998146653175354,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' surrounding',\n",
       "      'bytes': [32, 115, 117, 114, 114, 111, 117, 110, 100, 105, 110, 103],\n",
       "      'logprob': -0.9237463474273682,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' metropolitan',\n",
       "      'bytes': [32, 109, 101, 116, 114, 111, 112, 111, 108, 105, 116, 97, 110],\n",
       "      'logprob': -0.7537326216697693,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' area',\n",
       "      'bytes': [32, 97, 114, 101, 97],\n",
       "      'logprob': -0.11537419259548187,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' has',\n",
       "      'bytes': [32, 104, 97, 115],\n",
       "      'logprob': -0.8253042697906494,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.14300884306430817,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.00011427151912357658,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.20521360635757446,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' over',\n",
       "      'bytes': [32, 111, 118, 101, 114],\n",
       "      'logprob': -0.7601696848869324,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ', 'bytes': [32], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '31',\n",
       "      'bytes': [51, 49],\n",
       "      'logprob': -0.2526606619358063,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.00033534664544276893,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '3', 'bytes': [51], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Shanghai',\n",
       "      'bytes': [83, 104, 97, 110, 103, 104, 97, 105],\n",
       "      'logprob': -0.0006514362758025527,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',', 'bytes': [44], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' China',\n",
       "      'bytes': [32, 67, 104, 105, 110, 97],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -2.7968066206085496e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' This',\n",
       "      'bytes': [32, 84, 104, 105, 115],\n",
       "      'logprob': -2.0315074920654297,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' significant',\n",
       "      'bytes': [32, 115, 105, 103, 110, 105, 102, 105, 99, 97, 110, 116],\n",
       "      'logprob': -5.604132652282715,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Chinese',\n",
       "      'bytes': [32, 67, 104, 105, 110, 101, 115, 101],\n",
       "      'logprob': -3.659802198410034,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' city',\n",
       "      'bytes': [32, 99, 105, 116, 121],\n",
       "      'logprob': -0.11510223150253296,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' has',\n",
       "      'bytes': [32, 104, 97, 115],\n",
       "      'logprob': -0.02486325427889824,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.04796454682946205,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.03546455129981041,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.10616350919008255,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' around',\n",
       "      'bytes': [32, 97, 114, 111, 117, 110, 100],\n",
       "      'logprob': -1.336765170097351,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '27',\n",
       "      'bytes': [50, 55],\n",
       "      'logprob': -0.6700306534767151,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -9.829823102336377e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.003293686080724001,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '4', 'bytes': [52], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'SÃ£o',\n",
       "      'bytes': [83, 195, 163, 111],\n",
       "      'logprob': -0.008824214339256287,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Paulo',\n",
       "      'bytes': [32, 80, 97, 117, 108, 111],\n",
       "      'logprob': -3.128163257315464e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Brazil',\n",
       "      'bytes': [32, 66, 114, 97, 122, 105, 108],\n",
       "      'logprob': -3.128163257315464e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -4.084206375409849e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' The',\n",
       "      'bytes': [32, 84, 104, 101],\n",
       "      'logprob': -0.06496099382638931,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' largest',\n",
       "      'bytes': [32, 108, 97, 114, 103, 101, 115, 116],\n",
       "      'logprob': -0.04868876561522484,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' city',\n",
       "      'bytes': [32, 99, 105, 116, 121],\n",
       "      'logprob': -2.9160102712921798e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' in',\n",
       "      'bytes': [32, 105, 110],\n",
       "      'logprob': -5.512236498361744e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Brazil',\n",
       "      'bytes': [32, 66, 114, 97, 122, 105, 108],\n",
       "      'logprob': -0.0011767742689698935,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' has',\n",
       "      'bytes': [32, 104, 97, 115],\n",
       "      'logprob': -1.732335090637207,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.14317022264003754,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.05022067576646805,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.10268047451972961,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' about',\n",
       "      'bytes': [32, 97, 98, 111, 117, 116],\n",
       "      'logprob': -0.8661297559738159,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ', 'bytes': [32], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '22',\n",
       "      'bytes': [50, 50],\n",
       "      'logprob': -0.0002538296685088426,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -1.7432603272027336e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.0026121633127331734,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '5', 'bytes': [53], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Mexico',\n",
       "      'bytes': [77, 101, 120, 105, 99, 111],\n",
       "      'logprob': -0.009668259881436825,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' City',\n",
       "      'bytes': [32, 67, 105, 116, 121],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -5.512236498361744e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Mexico',\n",
       "      'bytes': [32, 77, 101, 120, 105, 99, 111],\n",
       "      'logprob': -4.320199877838604e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -2.8921695047756657e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' The',\n",
       "      'bytes': [32, 84, 104, 101],\n",
       "      'logprob': -0.08793538063764572,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' capital',\n",
       "      'bytes': [32, 99, 97, 112, 105, 116, 97, 108],\n",
       "      'logprob': -0.02959032729268074,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' and',\n",
       "      'bytes': [32, 97, 110, 100],\n",
       "      'logprob': -1.377675175666809,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' largest',\n",
       "      'bytes': [32, 108, 97, 114, 103, 101, 115, 116],\n",
       "      'logprob': -0.1996222287416458,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' city',\n",
       "      'bytes': [32, 99, 105, 116, 121],\n",
       "      'logprob': -0.00019448090461082757,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.6717119812965393,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Mexico',\n",
       "      'bytes': [32, 77, 101, 120, 105, 99, 111],\n",
       "      'logprob': -7.517272024415433e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' has',\n",
       "      'bytes': [32, 104, 97, 115],\n",
       "      'logprob': -0.38416922092437744,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.29461854696273804,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.023873891681432724,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.23555558919906616,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' around',\n",
       "      'bytes': [32, 97, 114, 111, 117, 110, 100],\n",
       "      'logprob': -0.779094934463501,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ', 'bytes': [32], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '21',\n",
       "      'bytes': [50, 49],\n",
       "      'logprob': -0.5771660804748535,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -7.584239938296378e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.00012106612848583609,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '6',\n",
       "      'bytes': [54],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'C',\n",
       "      'bytes': [67],\n",
       "      'logprob': -0.016227439045906067,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'airo',\n",
       "      'bytes': [97, 105, 114, 111],\n",
       "      'logprob': -2.7848862373502925e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Egypt',\n",
       "      'bytes': [32, 69, 103, 121, 112, 116],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -1.5451681974809617e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' The',\n",
       "      'bytes': [32, 84, 104, 101],\n",
       "      'logprob': -0.10254105180501938,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' largest',\n",
       "      'bytes': [32, 108, 97, 114, 103, 101, 115, 116],\n",
       "      'logprob': -0.17988693714141846,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' city',\n",
       "      'bytes': [32, 99, 105, 116, 121],\n",
       "      'logprob': -0.00012308525037951767,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' in',\n",
       "      'bytes': [32, 105, 110],\n",
       "      'logprob': -1.5570885807392187e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': -0.05330584570765495,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Arab',\n",
       "      'bytes': [32, 65, 114, 97, 98],\n",
       "      'logprob': -0.008746705949306488,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' world',\n",
       "      'bytes': [32, 119, 111, 114, 108, 100],\n",
       "      'logprob': -0.0004143456753809005,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.1378705501556396,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' with',\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'logprob': -0.1256500780582428,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.010007745586335659,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.013087762519717216,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.1990286111831665,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' over',\n",
       "      'bytes': [32, 111, 118, 101, 114],\n",
       "      'logprob': -1.7375586032867432,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '20',\n",
       "      'bytes': [50, 48],\n",
       "      'logprob': -0.0002788551209960133,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.00046165118692442775,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '7',\n",
       "      'bytes': [55],\n",
       "      'logprob': -4.320199877838604e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Mumbai',\n",
       "      'bytes': [77, 117, 109, 98, 97, 105],\n",
       "      'logprob': -0.2019975632429123,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -0.0011703446507453918,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' India',\n",
       "      'bytes': [32, 73, 110, 100, 105, 97],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**',\n",
       "      'bytes': [42, 42],\n",
       "      'logprob': -1.676292231422849e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -0.00010437761375214905,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' This',\n",
       "      'bytes': [32, 84, 104, 105, 115],\n",
       "      'logprob': -1.5152262449264526,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' financial',\n",
       "      'bytes': [32, 102, 105, 110, 97, 110, 99, 105, 97, 108],\n",
       "      'logprob': -0.9471909403800964,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' hub',\n",
       "      'bytes': [32, 104, 117, 98],\n",
       "      'logprob': -0.28707951307296753,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' has',\n",
       "      'bytes': [32, 104, 97, 115],\n",
       "      'logprob': -0.11574471741914749,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.006318732164800167,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.07169294357299805,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.13516074419021606,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' around',\n",
       "      'bytes': [32, 97, 114, 111, 117, 110, 100],\n",
       "      'logprob': -0.8051785230636597,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '20',\n",
       "      'bytes': [50, 48],\n",
       "      'logprob': -0.000540762091986835,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -1.6240566083070007e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.017236430197954178,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '8',\n",
       "      'bytes': [56],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Be',\n",
       "      'bytes': [66, 101],\n",
       "      'logprob': -8.149051427608356e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'ijing',\n",
       "      'bytes': [105, 106, 105, 110, 103],\n",
       "      'logprob': -1.6240566083070007e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' China',\n",
       "      'bytes': [32, 67, 104, 105, 110, 97],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -4.334533878136426e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' The',\n",
       "      'bytes': [32, 84, 104, 101],\n",
       "      'logprob': -0.01584114506840706,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' capital',\n",
       "      'bytes': [32, 99, 97, 112, 105, 116, 97, 108],\n",
       "      'logprob': -0.002583862515166402,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -1.1414541006088257,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' China',\n",
       "      'bytes': [32, 67, 104, 105, 110, 97],\n",
       "      'logprob': -1.4021237802808173e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.474700689315796,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' with',\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'logprob': -0.025826431810855865,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.01305339951068163,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.11592997610569,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.29019731283187866,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' approximately',\n",
       "      'bytes': [32,\n",
       "       97,\n",
       "       112,\n",
       "       112,\n",
       "       114,\n",
       "       111,\n",
       "       120,\n",
       "       105,\n",
       "       109,\n",
       "       97,\n",
       "       116,\n",
       "       101,\n",
       "       108,\n",
       "       121],\n",
       "      'logprob': -0.8901359438896179,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -1.8193366486229934e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '20',\n",
       "      'bytes': [50, 48],\n",
       "      'logprob': -0.08345776796340942,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.0049747284501791,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '9',\n",
       "      'bytes': [57],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': 0.0,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Dh',\n",
       "      'bytes': [68, 104],\n",
       "      'logprob': -0.00012403888104017824,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'aka',\n",
       "      'bytes': [97, 107, 97],\n",
       "      'logprob': -3.292907877039397e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Bangladesh',\n",
       "      'bytes': [32, 66, 97, 110, 103, 108, 97, 100, 101, 115, 104],\n",
       "      'logprob': -3.128163257315464e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**', 'bytes': [42, 42], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -1.0802738870552275e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' The',\n",
       "      'bytes': [32, 84, 104, 101],\n",
       "      'logprob': -0.44729211926460266,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' capital',\n",
       "      'bytes': [32, 99, 97, 112, 105, 116, 97, 108],\n",
       "      'logprob': -0.040603555738925934,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' and',\n",
       "      'bytes': [32, 97, 110, 100],\n",
       "      'logprob': -1.0316203832626343,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' largest',\n",
       "      'bytes': [32, 108, 97, 114, 103, 101, 115, 116],\n",
       "      'logprob': -0.043518394231796265,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' city',\n",
       "      'bytes': [32, 99, 105, 116, 121],\n",
       "      'logprob': -2.7252845029579476e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' with',\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'logprob': -3.995741367340088,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.10534490644931793,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.013786637224256992,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' of',\n",
       "      'bytes': [32, 111, 102],\n",
       "      'logprob': -0.5921308398246765,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' around',\n",
       "      'bytes': [32, 97, 114, 111, 117, 110, 100],\n",
       "      'logprob': -0.9515292048454285,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -3.128163257315464e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '20',\n",
       "      'bytes': [50, 48],\n",
       "      'logprob': -0.07827696949243546,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -2.935296834039036e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n',\n",
       "      'bytes': [46, 10],\n",
       "      'logprob': -0.0044641816057264805,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '10', 'bytes': [49, 48], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': '.', 'bytes': [46], 'logprob': 0.0, 'top_logprobs': []},\n",
       "     {'token': ' **',\n",
       "      'bytes': [32, 42, 42],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Os',\n",
       "      'bytes': [79, 115],\n",
       "      'logprob': -0.0003625177196227014,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'aka',\n",
       "      'bytes': [97, 107, 97],\n",
       "      'logprob': -2.522638169466518e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -1.2352385965641588e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Japan',\n",
       "      'bytes': [32, 74, 97, 112, 97, 110],\n",
       "      'logprob': -1.9361264946837764e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '**',\n",
       "      'bytes': [42, 42],\n",
       "      'logprob': -0.00040517066372558475,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' -',\n",
       "      'bytes': [32, 45],\n",
       "      'logprob': -0.016450734809041023,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Including',\n",
       "      'bytes': [32, 73, 110, 99, 108, 117, 100, 105, 110, 103],\n",
       "      'logprob': -3.1048829555511475,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' its',\n",
       "      'bytes': [32, 105, 116, 115],\n",
       "      'logprob': -0.5869931578636169,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' metropolitan',\n",
       "      'bytes': [32, 109, 101, 116, 114, 111, 112, 111, 108, 105, 116, 97, 110],\n",
       "      'logprob': -0.10107666999101639,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' area',\n",
       "      'bytes': [32, 97, 114, 101, 97],\n",
       "      'logprob': -0.0215163491666317,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ',',\n",
       "      'bytes': [44],\n",
       "      'logprob': -0.001846293918788433,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' it',\n",
       "      'bytes': [32, 105, 116],\n",
       "      'logprob': -0.28895696997642517,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' has',\n",
       "      'bytes': [32, 104, 97, 115],\n",
       "      'logprob': -0.012587227858603,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' a',\n",
       "      'bytes': [32, 97],\n",
       "      'logprob': -0.04395449534058571,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.0013392893597483635,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' close',\n",
       "      'bytes': [32, 99, 108, 111, 115, 101],\n",
       "      'logprob': -2.179447889328003,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' to',\n",
       "      'bytes': [32, 116, 111],\n",
       "      'logprob': -3.128163257315464e-07,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' ',\n",
       "      'bytes': [32],\n",
       "      'logprob': -0.001313213026151061,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '19',\n",
       "      'bytes': [49, 57],\n",
       "      'logprob': -0.0017245612107217312,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' million',\n",
       "      'bytes': [32, 109, 105, 108, 108, 105, 111, 110],\n",
       "      'logprob': -4.787507714354433e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.\\n\\n',\n",
       "      'bytes': [46, 10, 10],\n",
       "      'logprob': -0.0006888442439958453,\n",
       "      'top_logprobs': []},\n",
       "     {'token': 'Please',\n",
       "      'bytes': [80, 108, 101, 97, 115, 101],\n",
       "      'logprob': -0.3651162385940552,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' note',\n",
       "      'bytes': [32, 110, 111, 116, 101],\n",
       "      'logprob': -0.5173453688621521,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' that',\n",
       "      'bytes': [32, 116, 104, 97, 116],\n",
       "      'logprob': -0.008659843355417252,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' population',\n",
       "      'bytes': [32, 112, 111, 112, 117, 108, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.39809438586235046,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' figures',\n",
       "      'bytes': [32, 102, 105, 103, 117, 114, 101, 115],\n",
       "      'logprob': -0.1303013414144516,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' can',\n",
       "      'bytes': [32, 99, 97, 110],\n",
       "      'logprob': -1.182834267616272,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' vary',\n",
       "      'bytes': [32, 118, 97, 114, 121],\n",
       "      'logprob': -2.0049266815185547,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' and',\n",
       "      'bytes': [32, 97, 110, 100],\n",
       "      'logprob': -1.209532618522644,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' change',\n",
       "      'bytes': [32, 99, 104, 97, 110, 103, 101],\n",
       "      'logprob': -0.6609483957290649,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' over',\n",
       "      'bytes': [32, 111, 118, 101, 114],\n",
       "      'logprob': -0.4552079737186432,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' time',\n",
       "      'bytes': [32, 116, 105, 109, 101],\n",
       "      'logprob': -0.00011284107313258573,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' due',\n",
       "      'bytes': [32, 100, 117, 101],\n",
       "      'logprob': -0.3854701817035675,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' to',\n",
       "      'bytes': [32, 116, 111],\n",
       "      'logprob': -2.339278580620885e-06,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' new',\n",
       "      'bytes': [32, 110, 101, 119],\n",
       "      'logprob': -4.824253082275391,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' census',\n",
       "      'bytes': [32, 99, 101, 110, 115, 117, 115],\n",
       "      'logprob': -0.24156434834003448,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' data',\n",
       "      'bytes': [32, 100, 97, 116, 97],\n",
       "      'logprob': -0.003846151754260063,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' and',\n",
       "      'bytes': [32, 97, 110, 100],\n",
       "      'logprob': -0.8241434693336487,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' urban',\n",
       "      'bytes': [32, 117, 114, 98, 97, 110],\n",
       "      'logprob': -0.40624067187309265,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' development',\n",
       "      'bytes': [32, 100, 101, 118, 101, 108, 111, 112, 109, 101, 110, 116],\n",
       "      'logprob': -0.7053511738777161,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.',\n",
       "      'bytes': [46],\n",
       "      'logprob': -0.17713701725006104,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' Always',\n",
       "      'bytes': [32, 65, 108, 119, 97, 121, 115],\n",
       "      'logprob': -0.988764226436615,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' refer',\n",
       "      'bytes': [32, 114, 101, 102, 101, 114],\n",
       "      'logprob': -0.6524335741996765,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' to',\n",
       "      'bytes': [32, 116, 111],\n",
       "      'logprob': -3.4881879400927573e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': -0.011367048136889935,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' latest',\n",
       "      'bytes': [32, 108, 97, 116, 101, 115, 116],\n",
       "      'logprob': -0.3133120536804199,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' statistics',\n",
       "      'bytes': [32, 115, 116, 97, 116, 105, 115, 116, 105, 99, 115],\n",
       "      'logprob': -0.39702266454696655,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' for',\n",
       "      'bytes': [32, 102, 111, 114],\n",
       "      'logprob': -0.18434631824493408,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' the',\n",
       "      'bytes': [32, 116, 104, 101],\n",
       "      'logprob': -0.008705690503120422,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' most',\n",
       "      'bytes': [32, 109, 111, 115, 116],\n",
       "      'logprob': -4.632542913896032e-05,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' accurate',\n",
       "      'bytes': [32, 97, 99, 99, 117, 114, 97, 116, 101],\n",
       "      'logprob': -0.3785179853439331,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' and',\n",
       "      'bytes': [32, 97, 110, 100],\n",
       "      'logprob': -2.410654306411743,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' current',\n",
       "      'bytes': [32, 99, 117, 114, 114, 101, 110, 116],\n",
       "      'logprob': -0.8872332572937012,\n",
       "      'top_logprobs': []},\n",
       "     {'token': ' information',\n",
       "      'bytes': [32, 105, 110, 102, 111, 114, 109, 97, 116, 105, 111, 110],\n",
       "      'logprob': -0.24866990745067596,\n",
       "      'top_logprobs': []},\n",
       "     {'token': '.',\n",
       "      'bytes': [46],\n",
       "      'logprob': -0.0020619959104806185,\n",
       "      'top_logprobs': []}],\n",
       "    'refusal': None},\n",
       "   'message': {'content': 'As of my last knowledge update in October 2023, the most populated cities in the world can vary based on the criteria used (city proper, metropolitan area, or urban agglomeration). However, as of that time, here are generally considered some of the most populated cities (by metropolitan area):\\n\\n1. **Tokyo, Japan** - A major metropolitan area with a population of around 37 million.\\n2. **Delhi, India** - The capital city and its surrounding metropolitan area has a population of over 31 million.\\n3. **Shanghai, China** - This significant Chinese city has a population of around 27 million.\\n4. **SÃ£o Paulo, Brazil** - The largest city in Brazil has a population of about 22 million.\\n5. **Mexico City, Mexico** - The capital and largest city of Mexico has a population of around 21 million.\\n6. **Cairo, Egypt** - The largest city in the Arab world, with a population of over 20 million.\\n7. **Mumbai, India** - This financial hub has a population of around 20 million.\\n8. **Beijing, China** - The capital of China, with a population of approximately 20 million.\\n9. **Dhaka, Bangladesh** - The capital and largest city with a population of around 20 million.\\n10. **Osaka, Japan** - Including its metropolitan area, it has a population close to 19 million.\\n\\nPlease note that population figures can vary and change over time due to new census data and urban development. Always refer to the latest statistics for the most accurate and current information.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1740978802,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': 'fp_06737a9306',\n",
       " 'usage': {'completion_tokens': 327,\n",
       "  'prompt_tokens': 17,\n",
       "  'total_tokens': 344,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"the top 10 most populated cities are: \",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # model=\"davinci-002\",\n",
    "    logprobs=True\n",
    ")\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-VHczP7G4T1UdigXmu23YWrRv on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtell me a unique joke about death\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:879\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    876\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    877\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    878\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1296\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1284\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1291\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1292\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1293\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1294\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1295\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:973\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    971\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1062\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1061\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1111\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1107\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1108\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1109\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1062\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1061\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1111\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1107\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1108\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1109\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/ai/openai/mastering-openai-python-apis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1077\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1074\u001b[39m         err.response.read()\n\u001b[32m   1076\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1077\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1080\u001b[39m     cast_to=cast_to,\n\u001b[32m   1081\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1086\u001b[39m )\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-VHczP7G4T1UdigXmu23YWrRv on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"tell me a unique joke about death\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    n=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why donât skeletons fight each other?\\n\\nThey donât have the guts!',\n",
       " 'Why donât skeletons fight each other? \\n\\nThey donât have the guts!',\n",
       " 'Why did Death start a gardening business?\\n\\nBecause he wanted to help people make \"grave\" decisions!',\n",
       " \"Sure, here's a unique joke for you:\\n\\nWhy did death become a motivational speaker?\\n\\nBecause it always knew how to help people let go!\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[choice.message.content for choice in response.choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why donât skeletons fight each other?\\n\\nThey donât have the guts!',\n",
       " 'Why donât skeletons fight each other? \\n\\nThey donât have the guts!',\n",
       " 'Why did Death start a gardening business?\\n\\nBecause he wanted to help people make \"grave\" decisions!',\n",
       " \"Sure, here's a unique joke for you:\\n\\nWhy did death become a motivational speaker?\\n\\nBecause it always knew how to help people let go!\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[choice['message']['content'] for choice in response.model_dump()['choices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [choice.message.content for choice in response.choices] == [choice['message']['content'] for choice in response.model_dump()['choices']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
