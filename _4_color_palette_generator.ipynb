{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client:openai.OpenAI = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "## openai helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(client:openai.OpenAI, prompt:str, model:str='gpt-4o-mini', return_dict_body:bool=False, return_response_body:bool=False) -> str | dict | ChatCompletion:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # print(type(response))\n",
    "    \n",
    "    if return_response_body:\n",
    "        return response\n",
    "    if return_dict_body:\n",
    "        return response.model_dump()\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template interpolate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_prompt(prompt:str) -> str:\n",
    "    return f'''\n",
    "    You are a color palette generating assistant that responds to text prompts for color palettes\n",
    "    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\n",
    "    The palettes should be between 2 and 8 colors, the more the better.\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\n",
    "    A: [\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\n",
    "    A: [\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]\n",
    "\n",
    "\n",
    "    Desired Format: just a JSON array of hexadecimal color codes, nothing else before or after\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: {prompt}\n",
    "    A:    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook markdown display helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colors(colors, width:int=4):\n",
    "    display(\n",
    "        Markdown(\n",
    "            ' '.join(\n",
    "                f'<span style=\"color: {color}\">{chr(9608) * width}</span>'\n",
    "                for color in colors\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main\n",
    "## get json color array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"#003F5C\",\"#6B8EAD\",\"#A8DADC\",\"#F1FAEE\",\"#457B9D\"]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_llm_response(\n",
    "    client, \n",
    "    get_colors_prompt('blue ocean')\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert json to python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#003F5C', '#6B8EAD', '#A8DADC', '#F1FAEE', '#457B9D']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = json.loads(response)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #003F5C\">████</span> <span style=\"color: #6B8EAD\">████</span> <span style=\"color: #A8DADC\">████</span> <span style=\"color: #F1FAEE\">████</span> <span style=\"color: #457B9D\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_colors(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# macro helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_palette(client:openai.OpenAI, prompt:str) -> list:\n",
    "    userprompt = get_colors_prompt(prompt)\n",
    "    response = get_llm_response(client, userprompt)\n",
    "    colors = json.loads(response)\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "\n",
    "\n",
    "def show_palette(client:openai.OpenAI, prompt:str):\n",
    "    try:\n",
    "        colors = get_color_palette(client, prompt)\n",
    "        display_colors(colors)\n",
    "        print(colors)\n",
    "    except JSONDecodeError as jde:\n",
    "        print(f'something wrong with llm response format: {response!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #001F3F\">████</span> <span style=\"color: #003D5B\">████</span> <span style=\"color: #5B8FF3\">████</span> <span style=\"color: #2E8B57\">████</span> <span style=\"color: #A0DAB9\">████</span> <span style=\"color: #B8E3D2\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#001F3F', '#003D5B', '#5B8FF3', '#2E8B57', '#A0DAB9', '#B8E3D2']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'ocean abyss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something wrong with llm response format: '[\"#003F5C\",\"#6B8EAD\",\"#A8DADC\",\"#F1FAEE\",\"#457B9D\"]'\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'cyber terminal with green chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #F9E21B\">████</span> <span style=\"color: #F4B400\">████</span> <span style=\"color: #D20A0B\">████</span> <span style=\"color: #A200DD\">████</span> <span style=\"color: #0077C8\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#F9E21B', '#F4B400', '#D20A0B', '#A200DD', '#0077C8']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'spongebob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #C8102E\">████</span> <span style=\"color: #003DA5\">████</span> <span style=\"color: #FEDD00\">████</span> <span style=\"color: #FFFFFF\">████</span> <span style=\"color: #000000\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#C8102E', '#003DA5', '#FEDD00', '#FFFFFF', '#000000']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'superman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #FFFFFF\">████</span> <span style=\"color: #B0B3B7\">████</span> <span style=\"color: #7D7D7D\">████</span> <span style=\"color: #3B3B3B\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FFFFFF', '#B0B3B7', '#7D7D7D', '#3B3B3B']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'european tabby cat white gray and black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
