{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client:openai.OpenAI = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "## openai helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(client:openai.OpenAI, prompt:str, model:str='gpt-4o-mini', return_dict_body:bool=False, return_response_body:bool=False) -> str | dict | ChatCompletion:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # print(type(response))\n",
    "    \n",
    "    if return_response_body:\n",
    "        return response\n",
    "    if return_dict_body:\n",
    "        return response.model_dump()\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template interpolate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_prompt(prompt:str) -> str:\n",
    "    return f'''\n",
    "    You are a color palette generating assistant that responds to text prompts for color palettes\n",
    "    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\n",
    "    The palettes should be between 2 and 8 colors, the more the better.\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\n",
    "    A: [\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\n",
    "    A: [\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]\n",
    "\n",
    "\n",
    "    Desired Format: just a JSON array of hexadecimal color codes, nothing else before or after\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: {prompt}\n",
    "    A:    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook markdown display helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colors(colors, width:int=4):\n",
    "    display(\n",
    "        Markdown(\n",
    "            ' '.join(\n",
    "                f'<span style=\"color: {color}\">{chr(9608) * width}</span>'\n",
    "                for color in colors\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main\n",
    "## get json color array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"#003366\", \"#0077be\", \"#00aaff\", \"#99ccff\", \"#e0f7ff\"]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_llm_response(\n",
    "    client, \n",
    "    get_colors_prompt('blue ocean')\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert json to python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#003366', '#0077be', '#00aaff', '#99ccff', '#e0f7ff']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = json.loads(response)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #003366\">████</span> <span style=\"color: #0077be\">████</span> <span style=\"color: #00aaff\">████</span> <span style=\"color: #99ccff\">████</span> <span style=\"color: #e0f7ff\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_colors(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# macro helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_palette(client:openai.OpenAI, prompt:str) -> list:\n",
    "    userprompt = get_colors_prompt(prompt)\n",
    "    response = get_llm_response(client, userprompt)\n",
    "    colors = json.loads(response)\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "\n",
    "\n",
    "def show_palette(client:openai.OpenAI, prompt:str):\n",
    "    try:\n",
    "        colors = get_color_palette(client, prompt)\n",
    "        display_colors(colors)\n",
    "        print(colors)\n",
    "    except JSONDecodeError as jde:\n",
    "        print(f'something wrong with llm response format: {response!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #003B5C\">████</span> <span style=\"color: #005C99\">████</span> <span style=\"color: #008B8B\">████</span> <span style=\"color: #4FC3F7\">████</span> <span style=\"color: #A1C6EA\">████</span> <span style=\"color: #E0F7FA\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#003B5C', '#005C99', '#008B8B', '#4FC3F7', '#A1C6EA', '#E0F7FA']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'ocean abyss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #00FF00\">████</span> <span style=\"color: #000000\">████</span> <span style=\"color: #1A1A1A\">████</span> <span style=\"color: #4DFF4D\">████</span> <span style=\"color: #007F00\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#00FF00', '#000000', '#1A1A1A', '#4DFF4D', '#007F00']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'cyber terminal with green chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #F4D03F\">████</span> <span style=\"color: #F39C12\">████</span> <span style=\"color: #E74C3C\">████</span> <span style=\"color: #2980B9\">████</span> <span style=\"color: #2ECC71\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#F4D03F', '#F39C12', '#E74C3C', '#2980B9', '#2ECC71']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'spongebob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #C8102E\">████</span> <span style=\"color: #003DA5\">████</span> <span style=\"color: #FEC200\">████</span> <span style=\"color: #FFFFFF\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#C8102E', '#003DA5', '#FEC200', '#FFFFFF']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'superman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #FFFFFF\">████</span> <span style=\"color: #A9A9A9\">████</span> <span style=\"color: #7D7D7D\">████</span> <span style=\"color: #000000\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FFFFFF', '#A9A9A9', '#7D7D7D', '#000000']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'european tabby cat white gray and black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
