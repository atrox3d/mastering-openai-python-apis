{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client:openai.OpenAI = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "## openai helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(client:openai.OpenAI, prompt:str, model:str='gpt-4o-mini', return_dict_body:bool=False, return_response_body:bool=False) -> str | dict | ChatCompletion:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # print(type(response))\n",
    "    \n",
    "    if return_response_body:\n",
    "        return response\n",
    "    if return_dict_body:\n",
    "        return response.model_dump()\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template interpolate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_prompt(prompt:str) -> str:\n",
    "    return f'''\n",
    "    You are a color palette generating assistant that responds to text prompts for color palettes\n",
    "    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\n",
    "    The palettes should be between 2 and 8 colors, the more the better.\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\n",
    "    A: [\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\n",
    "    A: [\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]\n",
    "\n",
    "\n",
    "    Desired Format: just a JSON array of hexadecimal color codes, nothing else before or after\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: {prompt}\n",
    "    A:    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook markdown display helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colors(colors, width:int=4):\n",
    "    display(\n",
    "        Markdown(\n",
    "            ' '.join(\n",
    "                f'<span style=\"color: {color}\">{chr(9608) * width}</span>'\n",
    "                for color in colors\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main\n",
    "## get json color array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"#003F5C\", \"#2A7D8E\", \"#4FB3BF\", \"#A8D8EA\", \"#F1FAEE\"]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_llm_response(\n",
    "    client, \n",
    "    get_colors_prompt('blue ocean')\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert json to python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#003F5C', '#2A7D8E', '#4FB3BF', '#A8D8EA', '#F1FAEE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = json.loads(response)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #003F5C\">████</span> <span style=\"color: #2A7D8E\">████</span> <span style=\"color: #4FB3BF\">████</span> <span style=\"color: #A8D8EA\">████</span> <span style=\"color: #F1FAEE\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_colors(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# macro helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_palette(client:openai.OpenAI, prompt:str) -> list:\n",
    "    userprompt = get_colors_prompt(prompt)\n",
    "    response = get_llm_response(client, userprompt)\n",
    "    colors = json.loads(response)\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "\n",
    "\n",
    "def show_palette(client:openai.OpenAI, prompt:str):\n",
    "    try:\n",
    "        colors = get_color_palette(client, prompt)\n",
    "        display_colors(colors)\n",
    "        print(colors)\n",
    "    except JSONDecodeError as jde:\n",
    "        print(f'something wrong with llm response format: {response!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #001F3F\">████</span> <span style=\"color: #004D6D\">████</span> <span style=\"color: #013B48\">████</span> <span style=\"color: #005B77\">████</span> <span style=\"color: #0096A6\">████</span> <span style=\"color: #3CC3D3\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#001F3F', '#004D6D', '#013B48', '#005B77', '#0096A6', '#3CC3D3']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'ocean abyss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #00FF00\">████</span> <span style=\"color: #000000\">████</span> <span style=\"color: #1C1C1C\">████</span> <span style=\"color: #33CC33\">████</span> <span style=\"color: #66FF66\">████</span> <span style=\"color: #009900\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#00FF00', '#000000', '#1C1C1C', '#33CC33', '#66FF66', '#009900']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'cyber terminal with green chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #F9D94B\">████</span> <span style=\"color: #CD4E3D\">████</span> <span style=\"color: #3B7E9A\">████</span> <span style=\"color: #A7C6ED\">████</span> <span style=\"color: #FFC107\">████</span> <span style=\"color: #FF6F20\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#F9D94B', '#CD4E3D', '#3B7E9A', '#A7C6ED', '#FFC107', '#FF6F20']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'spongebob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #C8102E\">████</span> <span style=\"color: #F0F0F0\">████</span> <span style=\"color: #004B87\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#C8102E', '#F0F0F0', '#004B87']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'superman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: #FFFFFF\">████</span> <span style=\"color: #B0B0B0\">████</span> <span style=\"color: #404040\">████</span> <span style=\"color: #000000\">████</span> <span style=\"color: #AFAFAF\">████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FFFFFF', '#B0B0B0', '#404040', '#000000', '#AFAFAF']\n"
     ]
    }
   ],
   "source": [
    "show_palette(client, 'european tabby cat white gray and black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
